import feedparser
import requests
import time
import re
import os
import threading
from datetime import datetime, timedelta
from html import unescape
from flask import Flask

# ============================
#   Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª
# ============================

# ØªÙˆÙƒÙ† Ø¨ÙˆØª Ø§Ù„Ø±ÙŠØ§Ø¶Ø©
BOT_TOKEN = os.getenv("BOT_TOKEN", "8349529503:AAGj-SNuDNuhxmb22J13L9fkH_9DE1FFlIg")
# Ù‚Ù†Ø§Ø© Ø§Ù„Ø±ÙŠØ§Ø¶Ø©
CHAT_ID = os.getenv("CHAT_ID", "@F90Sports")

# Ù…ÙØªØ§Ø­ API-FOOTBALL (Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø°ÙŠ Ø£Ø¹Ø·ÙŠØªÙ†ÙŠ Ø¥ÙŠØ§Ù‡)
API_FOOTBALL_KEY = os.getenv(
    "API_FOOTBALL_KEY",
    "3caa9eece931b202667d7c0e71ebe84918e5ac75adc7669ea0522ef241326e6f"
)

# Ù„ÙˆØºÙˆ Ø§Ù„Ù‚Ù†Ø§Ø© ÙÙŠ Ø­Ø§Ù„ Ù…Ø§ ÙÙŠ ØµÙˆØ±Ø© Ù„Ù„Ø®Ø¨Ø±
LOGO_URL = "https://i.ibb.co/KzQK444K/file-00000000581871f5944b3ab066a737a1.png"

# Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø¨Ø§Ø± ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù… (RSS)
SOURCES = [
    # Ø¹Ø±Ø¨ÙŠ
    "https://www.kooora.com/xml/rss.aspx?cup=0&region=-1&team=0&tour=0",
    "https://www.yallakora.com/rss/288",
    # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
    "https://www.bbc.com/sport/football/rss.xml",
    "https://www.espn.com/espn/rss/soccer/news",
    "https://www.skysports.com/rss/12040",
    "https://www.goal.com/feeds/en/news",
    # ÙƒÙŠÙ†ØºØ² Ù„ÙŠØº â€“ ØºØ§Ù„Ø¨Ø§Ù‹ ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³
    "https://kingsleague.pro/feed/",
]

FOOTER = (
    "ğŸ“¢ Ø§Ù†Ø¶Ù…ÙˆØ§ Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø±ÙŠØ§Ø¶Ø© Ø§Ù„Ø£Ù‚ÙˆÙ‰ F90 Sports\n"
    "âš½ Ù†ØªØ§Ø¦Ø¬ØŒ Ø£Ø®Ø¨Ø§Ø±ØŒ Ø§Ù†ØªÙ‚Ø§Ù„Ø§ØªØŒ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ÙˆØ£ÙƒØ«Ø±â€¦\n"
    "ğŸ“¡ Ø§Ù„ØªÙ„Ø¬Ø±Ø§Ù…: https://t.me/F90Sports"
)

# Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ØªÙƒØ±Ø§Ø±
seen_links = set()
seen_titles = set()
SEEN_LIMIT = 5000

# ØªÙˆÙ‚ÙŠØª Ø¢Ø®Ø± Ù…Ù†Ø´ÙˆØ± Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…
last_fixtures_time = 0  # Ù…Ø±Ø© ÙƒÙ„ Ø³Ø§Ø¹Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰

# ============================
#   Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# ============================


def clean_html(raw: str) -> str:
    if not raw:
        return ""
    raw = unescape(raw)
    raw = re.sub(r"<[^>]+>", " ", raw)      # Ø¥Ø²Ø§Ù„Ø© HTML
    raw = re.sub(r"http\S+", "", raw)       # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø±ÙˆØ§Ø¨Ø·
    raw = re.sub(r"\s+", " ", raw).strip()
    return raw


def is_arabic(text: str) -> bool:
    return bool(re.search(r"[\u0600-\u06FF]", text or ""))


def translate_to_arabic(text: str) -> str:
    """ØªØ±Ø¬Ù…Ø© Ù†Øµ ØºÙŠØ± Ø¹Ø±Ø¨ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‚ØµÙŠØ±Ø§Ù‹ Ø£Ùˆ Ù…ØªÙˆØ³Ø·Ø§Ù‹)."""
    if not text:
        return ""
    if is_arabic(text):
        return text
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ±Ø¬Ù…Ø© Ø¬ÙˆØ¬Ù„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Ù…ÙØªÙˆØ­Ø©
        # (Ø¨Ø¯ÙˆÙ† Ù…ÙƒØªØ¨Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø­ØªÙ‰ Ù„Ø§ ÙŠØ­ØµÙ„ Ù…Ø´Ø§ÙƒÙ„ ØªÙ†ØµÙŠØ¨)
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",
            "sl": "auto",
            "tl": "ar",
            "dt": "t",
            "q": text,
        }
        r = requests.get(url, params=params, timeout=10)
        data = r.json()
        translated = "".join(part[0] for part in data[0])
        return translated
    except Exception:
        # Ø¥Ø°Ø§ Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙØ´Ù„Øª Ù†Ø±Ø¬Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
        return text


def get_full_text(entry) -> str:
    for key in ("summary", "description", "content"):
        if hasattr(entry, key):
            return clean_html(getattr(entry, key))
        if key in entry:
            return clean_html(entry[key])
    return ""


def get_image(entry):
    # Ù†Ø­Ø§ÙˆÙ„ Ø¬Ù„Ø¨ ØµÙˆØ±Ø© Ù…Ù† RSS
    for key in ("media_content", "media_thumbnail", "enclosures"):
        if key in entry:
            try:
                data = entry[key][0] if isinstance(entry[key], list) else entry[key]
                url = data.get("url") or data.get("href")
                if url and url.startswith("http") and not url.endswith(".mp4"):
                    return url
            except Exception:
                pass

    summary = getattr(entry, "summary", "") or getattr(entry, "description", "")
    m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', summary)
    if m:
        return m.group(1)

    # fallback: Ù„ÙˆØºÙˆ Ø§Ù„Ù‚Ù†Ø§Ø©
    return LOGO_URL


def get_video(entry):
    for key in ("media_content", "enclosures"):
        if key in entry:
            items = entry[key] if isinstance(entry[key], list) else [entry[key]]
            for it in items:
                url = it.get("url") or it.get("href")
                if url and url.startswith("http") and url.endswith(".mp4"):
                    return url

    summary = getattr(entry, "summary", "") or getattr(entry, "description", "")
    links = re.findall(r"(https?://\S+)", summary)
    for l in links:
        if l.endswith(".mp4"):
            return l

    return None


def get_entry_datetime(entry):
    for key in ("published_parsed", "updated_parsed"):
        if key in entry and entry[key]:
            try:
                tt = entry[key]
                return datetime(*tt[:6])
            except Exception:
                continue
    return None


def is_recent(entry, hours=24):
    dt = get_entry_datetime(entry)
    if not dt:
        return False
    return (datetime.utcnow() - dt) <= timedelta(hours=hours)


def shrink_seen_sets():
    global seen_links, seen_titles
    if len(seen_links) > SEEN_LIMIT:
        seen_links = set(list(seen_links)[-SEEN_LIMIT // 2:])
    if len(seen_titles) > SEEN_LIMIT:
        seen_titles = set(list(seen_titles)[-SEEN_LIMIT // 2:])


# ============================
#   Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
# ============================


def send_news(title, source, details, img=None, video=None, original_snippet=None):
    title_ar = translate_to_arabic(title)
    details = details.strip()
    if len(details) > 2000:
        details = details[:2000] + "..."

    details_ar = translate_to_arabic(details)

    if original_snippet and len(original_snippet) > 400:
        original_snippet = original_snippet[:400] + "..."

    caption = (
        f"ğŸ”´ <b>{title_ar}</b>\n\n"
        f"ğŸ“„ <b>Ø§Ù„ØªÙØ§ØµÙŠÙ„:</b>\n{details_ar}\n\n"
        f"ğŸ“° <b>Ø§Ù„Ù…ØµØ¯Ø±:</b> {source}"
    )

    if original_snippet and not is_arabic(original_snippet):
        caption += f"\n\nğŸŒ <b>Ù…Ù‚ØªØ·Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:</b>\n{original_snippet}"

    caption += FOOTER

    # ÙÙŠØ¯ÙŠÙˆ Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ù† ÙˆØ¬Ø¯
    if video:
        try:
            vdata = requests.get(video, timeout=15).content
            requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendVideo",
                data={"chat_id": CHAT_ID, "caption": caption, "parse_mode": "HTML"},
                files={"video": vdata},
                timeout=20,
            )
            return
        except Exception as e:
            print("âš ï¸ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:", e)

    # ØµÙˆØ±Ø©
    if img:
        try:
            pdata = requests.get(img, timeout=10).content
            requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto",
                data={"chat_id": CHAT_ID, "caption": caption, "parse_mode": "HTML"},
                files={"photo": pdata},
                timeout=20,
            )
            return
        except Exception as e:
            print("âš ï¸ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø©:", e)

    # Ù†Øµ ÙÙ‚Ø·
    try:
        requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            data={"chat_id": CHAT_ID, "text": caption, "parse_mode": "HTML"},
            timeout=20,
        )
    except Exception as e:
        print("âš ï¸ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†ØµÙŠØ©:", e)


# ============================
#   Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ… â€“ API-FOOTBALL
# ============================


def fetch_fixtures():
    """Ø¬Ù„Ø¨ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ… Ù…Ù† API-FOOTBALL (Ø£Ù‡Ù… Ø§Ù„Ø¯ÙˆØ±ÙŠØ§Øª)."""
    try:
        today = datetime.utcnow().strftime("%Y-%m-%d")
        url = f"https://v3.football.api-sports.io/fixtures?date={today}&timezone=Asia/Jerusalem"
        headers = {"x-apisports-key": API_FOOTBALL_KEY}
        res = requests.get(url, headers=headers, timeout=15)
        data = res.json()

        fixtures = data.get("response", [])
        if not fixtures:
            return None

        # Ù†Ù‡ØªÙ… ÙÙ‚Ø· Ø¨Ø§Ù„Ø¯ÙˆØ±ÙŠØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© + ÙƒÙŠÙ†ØºØ² Ù„ÙŠØº Ø¥Ù† ÙˆØ¬Ø¯Øª
        important_leagues = {
            "UEFA Champions League",
            "Premier League",
            "La Liga",
            "Serie A",
            "Bundesliga",
            "Ligue 1",
            "Saudi Professional League",
            "Kings League",
        }

        lines = []
        for fx in fixtures:
            league = fx["league"]["name"]
            if league not in important_leagues:
                continue

            home = fx["teams"]["home"]["name"]
            away = fx["teams"]["away"]["name"]
            status = fx["fixture"]["status"]["short"]
            t = fx["fixture"]["date"]  # ISO

            # ØªÙˆÙ‚ÙŠØª Ù…Ø¨Ø³Ø· HH:MM
            dt = datetime.fromisoformat(t.replace("Z", "+00:00"))
            time_str = dt.strftime("%H:%M")

            goals_home = fx["goals"]["home"]
            goals_away = fx["goals"]["away"]

            if status in ("NS", "TBD"):
                score = "Ù„Ù… ØªØ¨Ø¯Ø£ Ø¨Ø¹Ø¯"
            elif goals_home is None or goals_away is None:
                score = "Ø¬Ø§Ø±Ù Ø§Ù„Ù„Ø¹Ø¨"
            else:
                score = f"{goals_home} : {goals_away}"

            yt_query = f"{home} vs {away} live"
            yt_link = f"https://www.youtube.com/results?search_query={yt_query.replace(' ', '+')}"

            line = (
                f"ğŸŸ {league}\n"
                f"âš” {home} vs {away}\n"
                f"â° {time_str} | ğŸ”¢ Ø§Ù„Ù†ØªÙŠØ¬Ø©: {score}\n"
                f"ğŸ”— Ø¨Ø« (Ø¨Ø­Ø« ÙŠÙˆØªÙŠÙˆØ¨): {yt_link}\n"
                "â€”â€”â€”"
            )
            lines.append(line)

        if not lines:
            return None

        text = "ğŸ“† <b>Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ… â€“ Ø£Ù‡Ù… Ø§Ù„Ø¯ÙˆØ±ÙŠØ§Øª</b>\n\n" + "\n".join(lines)
        return text
    except Exception as e:
        print("âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª:", e)
        return None


def send_fixtures_if_needed():
    global last_fixtures_time
    now = time.time()
    # Ù…Ø±Ø© ÙƒÙ„ Ø³Ø§Ø¹Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
    if now - last_fixtures_time < 3600:
        return

    fx_text = fetch_fixtures()
    if not fx_text:
        return

    try:
        requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            data={"chat_id": CHAT_ID, "text": fx_text, "parse_mode": "HTML"},
            timeout=20,
        )
        last_fixtures_time = now
        print("ğŸ“Š ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ù…Ù†Ø´ÙˆØ± Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ….")
    except Exception as e:
        print("âš ï¸ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ù…Ù†Ø´ÙˆØ± Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª:", e)


# ============================
#   Ø­Ù„Ù‚Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
# ============================


def run_bot():
    print("ğŸš€ F90 Sports Bot ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†â€¦")
    while True:
        shrink_seen_sets()
        send_fixtures_if_needed()
        new_count = 0

        for url in SOURCES:
            try:
                feed = feedparser.parse(url)
                source = feed.feed.get("title", "Ù…ØµØ¯Ø± Ø±ÙŠØ§Ø¶ÙŠ")

                for entry in reversed(feed.entries):
                    if not is_recent(entry, hours=24):
                        continue

                    link = entry.get("link", "")
                    if not link:
                        continue

                    title = clean_html(entry.get("title", "Ø®Ø¨Ø± Ø±ÙŠØ§Ø¶ÙŠ Ø¹Ø§Ø¬Ù„"))
                    if not title:
                        continue

                    key_title = title.lower()
                    if link in seen_links or key_title in seen_titles:
                        continue

                    details = get_full_text(entry)
                    if len(details) < 30:
                        continue

                    img = get_image(entry)
                    vid = get_video(entry)

                    snippet = details[:300]

                    send_news(title, source, details, img, vid, original_snippet=snippet)

                    seen_links.add(link)
                    seen_titles.add(key_title)
                    new_count += 1

                    time.sleep(2)

            except Exception as e:
                print("âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±:", url, e)

        if new_count == 0:
            print("â¸ï¸ Ù„Ø§ Ø£Ø®Ø¨Ø§Ø± Ø±ÙŠØ§Ø¶ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ø¢Ù†ØŒ Ø§Ù†ØªØ¸Ø§Ø± 60 Ø«Ø§Ù†ÙŠØ©â€¦")

        time.sleep(60)


# ============================
#   Flask Ù„ÙŠØ¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØª Ø­ÙŠ Ø¹Ù„Ù‰ Render
# ============================

app = Flask(__name__)


@app.route("/")
def home():
    return "âœ… F90 Sports Bot ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† 24/7 â€“ Ø£Ø®Ø¨Ø§Ø± + Ù†ØªØ§Ø¦Ø¬ + Ù…ÙˆØ§Ø¹ÙŠØ¯."


@app.route("/test")
def test():
    test_msg = (
        "âš½ <b>Ù…Ù†Ø´ÙˆØ± ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ù† F90 Sports Bot</b>\n\n"
        "Ø¥Ø°Ø§ ÙˆØµÙ„ØªÙƒ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ÙÙŠ Ù‚Ù†Ø§Ø© Ø§Ù„Ø±ÙŠØ§Ø¶Ø©ØŒ ÙØ§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­ âœ…\n"
        f"{FOOTER}"
    )
    try:
        requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            data={"chat_id": CHAT_ID, "text": test_msg, "parse_mode": "HTML"},
            timeout=20,
        )
    except Exception as e:
        return f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}"
    return "ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø©."


def run_flask():
    app.run(host="0.0.0.0", port=8080)


if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    run_bot()
